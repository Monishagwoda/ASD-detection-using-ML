# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i8PlajOZC7sTmwjxy6-WijkB0uedorwy
"""

from google.colab import drive
drive.mount("/content/drive")

!pwd

!ls /content/drive/MyDrive/archive/ (9)

! pip install split_folders

# Commented out IPython magic to ensure Python compatibility.
# Importing necessary libraries
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
import tensorflow as tf
import seaborn as sns
import random
import os
import gc
import shutil
import splitfolders
import itertools
import datetime
import matplotlib.image as mping

from tqdm.notebook import tqdm
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy("float32")
from tensorflow.keras.models import Model, load_model, Sequential
from tensorflow.keras import optimizers
from tensorflow.keras import regularizers
from tensorflow.keras.utils import to_categorical

from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation
from tensorflow.keras.layers import Conv2D, MaxPooling2D, SeparableConv2D, BatchNormalization


from tensorflow.keras.applications.vgg16 import VGG16

from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.preprocessing import image_dataset_from_directory

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import precision_recall_curve
from mlxtend.plotting import plot_confusion_matrix

"""Load Data"""

# Creating file path for our train data and test data
train_dir = "/content/drive/MyDrive/archive (9)/AutismDataset/train"
test_dir = "/content/drive/MyDrive/archive (9)/AutismDataset/test"

"""Data Preprocessing"""

from sklearn.preprocessing import LabelEncoder
# Define the path to your dataset directory
dataset_dir = '/content/drive/MyDrive/archive (9)/AutismDataset/consolidated'
# Initialize empty lists to store images and labels
X = []
y = []

label_encoder = LabelEncoder()

# Iterate through each directory (assuming each directory represents a class)
for label in os.listdir(dataset_dir):
    label_dir = os.path.join(dataset_dir, label)
    # Iterate through each image in the directory
    for image_name in os.listdir(label_dir):
        img_path = os.path.join(label_dir, image_name)
        # Read and preprocess the image
        img = cv2.imread(img_path)
        if img is not None:  # Check if the image was read successfully
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (224, 224))
            X.append(img)
            y.append(label)  # Use directory name as label
        else:
            print(f"Warning: Unable to read image '{img_path}'")

# Convert lists to numpy arrays
X = np.array(X)
y = np.array(y)

y = label_encoder.fit_transform(y)


# Convert labels to one-hot encoding
# Assuming you have two classes, if more, adjust num_classes accordingly
num_classes = 2  # Change it according to your dataset
y = to_categorical(y, num_classes=num_classes)

# Split dataset into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)


train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest'
)

train_datagen.fit(X_train)

# Preprocessed data is ready to use for training

# Getting 'Autistic' and 'Non-Autistic' train images from respective file names of train data
train_non_autistic = [os.path.join(train_dir, i) for i in os.listdir(train_dir) if 'Non_Autistic' in i]
train_autistic = [os.path.join(train_dir, i) for i in os.listdir(train_dir) if 'Non_Autistic' not in i]

# Getting test images from test data file path
test_imgs = [os.path.join(test_dir, i) for i in os.listdir(test_dir)]

# Concatenate 'Autistic' and 'Non-Autistic' images and shuffle them as train_images
train_imgs = train_autistic + train_non_autistic
random.shuffle(train_imgs)

# Remove the lists to save space
del train_autistic
del train_non_autistic
gc.collect()

# Define a variable to keep track of the index of the last displayed image
last_index = 0

# Plot the next 3 images from train_imgs
for img_path in train_imgs[last_index:last_index+3]:
    img = plt.imread(img_path)
    plt.imshow(img)
    plt.axis('off')  # Remove axes
    plt.show()

# Update the last_index variable for the next run
last_index += 3

# Define the dimensions for images
image_height = 150
image_width = 150
channels = 3

# Define the function to process images
def process_images(image_list):
    resized_images = []
    labels = []

    for img_path in image_list:
      img = cv2.imread(img_path, cv2.IMREAD_COLOR)

    # Check if the image was read successfully
    if img is None:
        print(f"Error reading image: {img_path}")
    else:
        resized_img = cv2.resize(img, (image_height, image_width), interpolation=cv2.INTER_CUBIC)
        resized_images.append(resized_img)

        if 'Non_Autistic' in img_path:
            labels.append(0)
        else:
            labels.append(1)

    return resized_images, labels

train_imgs = ['/content/drive/MyDrive/archive (9)/AutismDataset/train' + img_name for img_name in os.listdir('/content/drive/MyDrive/archive (9)/AutismDataset/train')]
# Get resized images and labels from train data
resized_images_train, labels_train = process_images(train_imgs)

# Delete train images to save space
del train_imgs
gc.collect()

# Define the image dimensions
img_width, img_height = 128, 128
input_shape = (img_width, img_height, 3)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

"""DenseNet"""

from tensorflow.keras.layers import Input, Concatenate, AveragePooling2D

# Define dense_block and transition_block functions
def dense_block(x, blocks, growth_rate):
    for i in range(blocks):
        x1 = BatchNormalization()(x)
        x1 = Activation('relu')(x1)
        x1 = Conv2D(4 * growth_rate, 1, padding='same', kernel_initializer='he_normal')(x1)
        x1 = BatchNormalization()(x1)
        x1 = Activation('relu')(x1)
        x1 = Conv2D(growth_rate, 3, padding='same', kernel_initializer='he_normal')(x1)
        x = Concatenate()([x, x1])
    return x

def transition_block(x, reduction):
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = Conv2D(int(tf.keras.backend.int_shape(x)[-1] * reduction), 1, padding='same', kernel_initializer='he_normal')(x)
    x = AveragePooling2D(2, strides=2)(x)
    return x

# Define DenseNet-201 architecture
def dense_net(blocks, growth_rate, num_classes):
    input_layer = Input(shape=input_shape)
    x = Conv2D(64, 7, strides=2, padding='same', kernel_initializer='he_normal')(input_layer)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(3, strides=2, padding='same')(x)

    for i in range(len(blocks)):
        x = dense_block(x, blocks[i], growth_rate)
        if i < len(blocks) - 1:
            x = transition_block(x, 0.5)

    # Modified average pooling
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = AveragePooling2D(pool_size=4)(x)

    x = Flatten()(x)
    x = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=input_layer, outputs=x)
    return model



# Define DenseNet-201 parameters
blocks = [6, 12, 48, 32]  # DenseNet-201 configuration
growth_rate = 32
num_classes = 2


# Create DenseNet-201 model (same as before)
model = dense_net(blocks, growth_rate, num_classes)

import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.models import load_model

# Define the image dimensions
img_width, img_height = 150, 150

batch_size = 64

# Define augmentation parameters
datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load and augment images from directories
train_generator = datagen.flow_from_directory(
    '/content/drive/MyDrive/archive (9)/AutismDataset/consolidated',
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical'
)

validation_generator = datagen.flow_from_directory(
    '/content/drive/MyDrive/archive (9)/AutismDataset/valid',
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical'
)

# Define the model
model = dense_net(blocks, growth_rate, num_classes) # You need to define your model creation function

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Define EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)

# Define ReduceLROnPlateau callback
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

# Checkpoint path
checkpoint_path = "/content/drive/MyDrive/training_1/cp.ckpt"

# Create a callback that saves the model's weights
cp_callback = ModelCheckpoint(filepath=checkpoint_path,
                              save_weights_only=True,
                              verbose=1)

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=100,  # Increased number of epochs
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    callbacks=[early_stopping, cp_callback, reduce_lr]  # Add the EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau callbacks
)

# Get resized images and labels from train data
X_train, y_train = read_and_process_image(train_imgs)

# Delete train images to save space
del train_imgs
gc.collect()

loc="/content/drive/MyDrive/AutismDataset/consolidated"
os.makedirs('output', exist_ok=True)
os.makedirs('output/train', exist_ok=True)
os.makedirs('output/val', exist_ok=True)
os.makedirs('output/test', exist_ok=True)
splitfolders.ratio(loc,output = "output",seed = 42,ratio = (0.80,.1,.1))

len(os.listdir("/content/drive/MyDrive/AutismDataset/consolidated/Non_Autistic")), len(os.listdir("/content/drive/MyDrive/AutismDataset/consolidated/Autistic"))

train_dir="output/train"
test_dir="output/test"
val_dir="output/val"
train_data=image_dataset_from_directory(train_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=True,seed=42)
test_data=image_dataset_from_directory(test_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=False,seed=42)
val_data=image_dataset_from_directory(val_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=False,seed=42)

class_names=train_data.class_names
class_count=len(class_names)

samples = []
x = 0
for i in tqdm(train_data.unbatch()):
    if (x == 10):
        break
    samples.append([i[0], i[1]])
    x += 1

images = []
labels = []
for i in samples:
    images.append(i[0])
    labels.append(class_names[tf.argmax(i[1])])
len(images), len(labels)

fig = plt.figure(figsize=(20, 8))
rows = 2
cols = 5
x = 1
for image, label in zip(images, labels):
    fig.add_subplot(rows, cols, x)
    plt.imshow(image/255.)
    plt.axis("off")
    plt.title(label)
    x += 1

input_shape = (224, 224, 3)

def create_early_stopper():
    earlystopper = tf.keras.callbacks.EarlyStopping(monitor="val_accuracy",
                                                    patience=3,
                                                    restore_best_weights=True,
                                                    min_delta=0.001,
                                                    verbose=1)
    return earlystopper

"""NASNetMobile"""

model_name = 'NASNetMobile'
base_model = tf.keras.applications.NASNetMobile(
    include_top=False, weights="imagenet", input_shape=(224, 224, 3), pooling='max')

x = base_model.output

x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.002)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(rate=0.45, seed=42)(x)
output = Dense(class_count, activation='softmax')(x)

model=Model(inputs=base_model.input, outputs=output)
model.compile(tf.keras.optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])

early_stopper = tf.keras.callbacks.EarlyStopping(patience=5, min_delta=0.01, verbose=1)

history = model.fit(train_data,
                    epochs=30,
                    validation_data=val_data,
                    callbacks=[early_stopper]
                   )

# Convert the lists to array
sns.set_palette(sns.color_palette(["b", "r"]))
plt.figure(figsize=(12, 8))
X_train = np.array(X_train)
y_train = np.array(y_train)
sns.countplot(y_train, saturation=1)
plt.title("Train image labels");

# Shape of train images and labels
print("Shape of train images:", X_train.shape)
print("Shape of train labels:", y_train.shape)

# Repeat the above process for validation data to get val_images
val_autistic = "/content/drive/MyDrive/AutismDataset/valid/Autistic"
val_non_autistic = "/content/drive/MyDrive/AutismDataset/valid/Non_Autistic"
val_autistic_imgs = ["/content/drive/MyDrive/AutismDataset/valid/Autistic/{}".format(i) for i in os.listdir(val_autistic)]
val_non_autistic_imgs = ["/content/drive/MyDrive/AutismDataset/valid/Non_Autistic/{}".format(i) for i in os.listdir(val_non_autistic)]
val_imgs = val_autistic_imgs + val_non_autistic_imgs
random.shuffle(val_imgs)

# Remove the lists to save space
del val_autistic_imgs
del val_non_autistic_imgs
gc.collect()

# Get resized images and labels from validation data
X_val, y_val = read_and_process_image(val_imgs)

# Delete validation images to save space
del val_imgs
gc.collect()

# Convert the lists to array
plt.figure(figsize=(12, 8))
X_val = np.array(X_val)
y_val = np.array(y_val)
sns.countplot(y_val, saturation=1)
plt.title("Validation image labels")

# Shape of validation images and labels
print("Shape of validation images:", X_val.shape)
print("Shape of validation labels:", y_val.shape)

# Get length of train data and validation data
ntrain = len(X_train)
nval = len(X_val)
batch_size = 32

# Calling pre-trained VGG16 model
base_model = VGG16(include_top=False,weights='/content/drive/MyDrive/vgg16_weights_tf_dim_ordering_tf_kernels_notop (1) (1).h5',input_shape=(150,150,3))

# Freeze the layers in pre-trained model, we don't need to train again
for layer in base_model.layers:
   layer.trainable = False

# Let's see how many layers are in the vgg model
print("Number of layers in the base model: ", len(base_model.layers))

# Create our classifier model, connect pre-trained model vgg to our model
model = keras.models.Sequential()
model.add(base_model)
model.add(layers.Flatten())
model.add(layers.Dense(512, activation = 'relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation = 'sigmoid'))

# Create summary of our model
model.summary()

# Compile the model specifying optimizer, loss function and metrics
model.compile(loss = 'binary_crossentropy', optimizer = keras.optimizers.Adam(), metrics = ['acc'])

# Configure data augumentation and scaling of images to prevent overfitting since we have a small train data
train_datagen = ImageDataGenerator(rescale = 1./255,
                                  rotation_range = 40,
                                  width_shift_range = 0.2,
                                  height_shift_range = 0.2,
                                  shear_range = 0.2,
                                  zoom_range = 0.2,
                                  horizontal_flip = True)

# Only rescaling for validation data
val_datagen = ImageDataGenerator(rescale = 1./255)

# Create test and validation image generator
train_generator = train_datagen.flow(X_train, y_train, batch_size = batch_size)
val_generator = val_datagen.flow(X_val, y_val, batch_size = batch_size)

# Train the model
history = model.fit(train_generator,
                              steps_per_epoch=ntrain // batch_size,
                              epochs=20,
                              validation_data=val_generator,
                              validation_steps=nval // batch_size
                             )

# Learning curves for training and validation
history_df = pd.DataFrame(history.history)
history_df

# Plot train and validation accuracy
plt.figure(figsize=(12, 8))
sns.lineplot(data=history_df.loc[:, ["acc", "val_acc"]], palette=['b', 'r'], dashes=False)
sns.set_style("whitegrid")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training and Validation Accuracy")

# Plot train and validation loss
plt.figure(figsize=(12, 8))
sns.lineplot(data=history_df.loc[:, ["loss", "val_loss"]], palette=['b', 'r'], dashes=False)
sns.set_style("whitegrid")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training and Validation Loss")

# Read and resize test images
random.shuffle(test_imgs)
X_test, y_test = read_and_process_image(test_imgs)
X = np.array(X_test)
#test_datagen = ImageDataGenerator(rescale = 1./255)

# Predict label for test images
pred = model.predict(X)
threshold = 0.5
predictions = np.where(pred > threshold, 1,0)
#print(predictions)

# Plot test images and their corresponding predictions
test = pd.DataFrame(data = predictions, columns = ["predictions"])
test
test["filename"] = [os.path.basename(i) for i in test_imgs]
test["test_labels"] = y_test
test = test[["filename", "test_labels", "predictions"]]
test

# Plotting the predictied label count in each class
plt.figure(figsize=(12, 8))
sns.countplot(test["predictions"], saturation=1)

# Generating Classification report for model's performance in each class
cl_report = classification_report(y_test, predictions)
print(cl_report)

# Generating Confusion Matrix for the predictions against true labels
cn_matrix= confusion_matrix(y_test, predictions)
cn_matrix

# Plotting the True Positives, True Negatives, False Positives and False Negatives from model's predictions
f, ax = plt.subplots(figsize = (8,6))
ax = sns.heatmap(cn_matrix, annot=True)
ax.set_xlabel("Predicted")
ax.set_ylabel("True")
ax.set_title("Confusion Matrix")

# Let's plot the AUC-ROC curve to assess the performance of our model
fpr, tpr, _ = roc_curve(y_test, predictions)
roc_auc= auc(fpr, tpr)

plt.figure(figsize = (10,8))
plt.plot(fpr, tpr, color = 'red', lw = 2, label = 'ROC curve (area = %0.2f)' % roc_auc)
plt.plot([1,0], [1,0], color = 'navy', lw = 2, linestyle = '--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Receiver Operating Characteristic curve")
plt.legend(loc = 'lower right')

# Let's check our predcitions against some test images
plt.figure(figsize=(4,4))
for val, i in enumerate(test_imgs[:10]):
    img = mpimg.imread(i)
    imgplot = plt.imshow(img)
    plt.title(os.path.basename(i) + ' - Prediction: ' +  f"{'Autistic' if predictions[val] == 1 else 'Non-Autistic'}")
    plt.show()